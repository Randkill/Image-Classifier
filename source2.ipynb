{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "source.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ3je0EdpQ4D",
        "colab_type": "text"
      },
      "source": [
        "## step 1\n",
        "\n",
        "connect *source*.*ipynb* to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpJ0pjfepO8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print('project is connected to DRIVE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QusOn6m0pheB",
        "colab_type": "text"
      },
      "source": [
        "## step 2\n",
        " change directory of workspace to **./drive/My Drive/erfan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd1xCMAwpedr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "%cd ./drive/My Drive/erfan\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BE3zbcwvimk",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries \n",
        "**keras** : using *keras* as a high level accessibility to *tensorflow*\n",
        "\n",
        "**numpy** : using numpy in order to process images as matrices\n",
        "\n",
        "**pandas** : using pandas for making *data_frame* from our *Corel* dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5wSZ_jJvjLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print('Libraries Imported')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTXJ5js-xW00",
        "colab_type": "text"
      },
      "source": [
        "## step 3\n",
        "read .CSV file in order to access *Corel* dataset and also converting it to a *string* format\n",
        "\n",
        "[]((https://drive.google.com/open?id=132knE84o-7yzrvGPbjwXuftWmb6oKtf4) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH6oMVsNxZxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"./Corel/newtrain2.csv\", dtype = str)     \n",
        "print('train.csv read!')\n",
        "#print(df[\"class\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQF5E3n_0A5h",
        "colab_type": "text"
      },
      "source": [
        "## step 4\n",
        "\n",
        "defining datas including *train_generator* (variable for our training data which is all of 10000 images from *Corel* dataset), *test_generator* (variable for our testing data) and *valid_generator* (variable for validation data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZB989t_zW_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.)             #rescaling pixels (/255) for easier use and process\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)        #rescaling pixels (/255) for easier use and process\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = df[:8000],\n",
        "    directory = \"./Corel\",\n",
        "    x_col = \"image\",\n",
        "    y_col = \"class\",\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"rgb\"\n",
        ")\n",
        "\n",
        "valid_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe = df[8001:9000],\n",
        "    directory= \"./Corel\",\n",
        "    x_col = \"image\",\n",
        "    y_col = \"class\",\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"rgb\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe = df[9001:10000],\n",
        "    directory= \"./Corel\",\n",
        "    x_col = \"image\",\n",
        "    y_col = \"class\",\n",
        "    batch_size = 32,\n",
        "    seed = 42,\n",
        "    shuffle = True,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"rgb\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS27H_lbqhJf",
        "colab_type": "text"
      },
      "source": [
        "## step 5\n",
        "\n",
        "Designing a **Neural** **Network** model for training data in a format of **Sequential** model\n",
        "input shape is (256, 256, 3) which : \n",
        "\n",
        "256*256 = the default format of our data_generators\n",
        "\n",
        "3 = the color channels which are ''RGB'\n",
        "\n",
        "and also the output of model is : (100) which are the 100 classes of our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2WcORY6qjdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(256,256,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dense(100, activation='sigmoid'))\n",
        "model.add(Dense(80, activation='softmax'))\n",
        "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.input_shape)\n",
        "print(model.output_shape)\n",
        "print('model designed!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xin4GID0qq9G",
        "colab_type": "text"
      },
      "source": [
        "## step 6\n",
        "fitting the model which is traing our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENgJgivqt-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\"\"\"\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    epochs=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyzWDpTTAT_O",
        "colab_type": "text"
      },
      "source": [
        "## step 7\n",
        "predicting our data\n",
        "\n",
        "First, we should reset *test_generator*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9PQNSS7AWsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "steps=STEP_SIZE_TEST,\n",
        "verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfDPmSUATNYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('lenght of prediction : ',len(pred))\n",
        "print('predictions : \\n',pred)\n",
        "print(len(test_generator.filenames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbRUoeTpAmGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_bool = (pred >0.007)\n",
        "predictions = []\n",
        "labels = train_generator.class_indices\n",
        "print('labels : ', labels)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print('lenght : ', len(labels))\n",
        "\n",
        "for row in pred_bool:\n",
        "    l=[]\n",
        "    for index,cls in enumerate(row):\n",
        "        if cls:\n",
        "            l.append(labels[index])\n",
        "    predictions.append(\",\".join(l))\n",
        "print('preditcionts : ', predictions, '\\nit`s lenght :', len(predictions))\n",
        "filenames=test_generator.filenames\n",
        "print('preditcionts : ', predictions, '\\nit`s lenght :', len(predictions))\n",
        "print('filenames : ', filenames, '\\nit`s lenght :', len(filenames))\n",
        "results=pd.DataFrame({\"image\":filenames,\"class\":predictions})\n",
        "print('done 1st!')\n",
        "results.to_csv(\"results.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}